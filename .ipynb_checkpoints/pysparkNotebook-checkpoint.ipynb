{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run TreePrinter.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/usr/local/spark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install mssql pyspark pyodbc pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pyspark,pyodbc \n",
    "    from pyspark import SparkContext, SparkConf, SQLContext\n",
    "    import _mssql\n",
    "    import pandas as pd\n",
    "except ImportError as e:\n",
    "     !{sys.executable} -m pip install pyspark pyodbc _mssql pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data from mysql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark_session = SparkSession.builder.config(\"spark.jars\", \"/home/mosaico/Documents/mosaico/sqljdbc_8.2/mysql-connector-java-8.0.22.jar\").master(\"local\").appName(\"PySpark_MySQL_test\").enableHiveSupport().getOrCreate()\n",
    "\n",
    "\n",
    "studenti = spark_session.read.format(\"jdbc\").option(\"url\", \"jdbc:mysql://localhost:3306/mosaico\") \\\n",
    "    .option(\"driver\", \"com.mysql.jdbc.Driver\").option(\"dbtable\", \"INFORMATION_SCHEMA.TABLES\") \\\n",
    "    .option(\"user\", \"PanDario\").option(\"password\", \"Mosaico2020\").load()\n",
    "studenti.show(vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark_session = SparkSession.builder.appName(\"DataframeFromJson\").enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases=spark_session.read.csv(\"assets/COVID-DATA/Case.csv\", sep=\",\", inferSchema=\"true\", header=\"true\")\n",
    "cases = cases.withColumnRenamed(\"infection_case\",\"infectionSource\")\n",
    "cases = cases.withColumnRenamed(\" case_id\",\"caseID\")\n",
    "regions = spark_session.read.csv(\"assets/COVID-DATA/Region.csv\", sep=\",\", inferSchema=\"true\", header=\"true\")\n",
    "cases = cases.withColumnRenamed(\"elementary_school_count\",\"elementarySchoolCount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caseID</th>\n",
       "      <th>province</th>\n",
       "      <th>city</th>\n",
       "      <th>group</th>\n",
       "      <th>infectionSource</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>Yongsan-gu</td>\n",
       "      <td>True</td>\n",
       "      <td>Itaewon Clubs</td>\n",
       "      <td>139</td>\n",
       "      <td>37.538621</td>\n",
       "      <td>126.992652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000002</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>Gwanak-gu</td>\n",
       "      <td>True</td>\n",
       "      <td>Richway</td>\n",
       "      <td>119</td>\n",
       "      <td>37.48208</td>\n",
       "      <td>126.901384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000003</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>Guro-gu</td>\n",
       "      <td>True</td>\n",
       "      <td>Guro-gu Call Center</td>\n",
       "      <td>95</td>\n",
       "      <td>37.508163</td>\n",
       "      <td>126.884387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000004</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>Yangcheon-gu</td>\n",
       "      <td>True</td>\n",
       "      <td>Yangcheon Table Tennis Club</td>\n",
       "      <td>43</td>\n",
       "      <td>37.546061</td>\n",
       "      <td>126.874209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000005</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>Dobong-gu</td>\n",
       "      <td>True</td>\n",
       "      <td>Day Care Center</td>\n",
       "      <td>43</td>\n",
       "      <td>37.679422</td>\n",
       "      <td>127.044374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000006</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>Guro-gu</td>\n",
       "      <td>True</td>\n",
       "      <td>Manmin Central Church</td>\n",
       "      <td>41</td>\n",
       "      <td>37.481059</td>\n",
       "      <td>126.894343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000007</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>from other city</td>\n",
       "      <td>True</td>\n",
       "      <td>SMR Newly Planted Churches Group</td>\n",
       "      <td>36</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000008</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>Dongdaemun-gu</td>\n",
       "      <td>True</td>\n",
       "      <td>Dongan Church</td>\n",
       "      <td>17</td>\n",
       "      <td>37.592888</td>\n",
       "      <td>127.056766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000009</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>from other city</td>\n",
       "      <td>True</td>\n",
       "      <td>Coupang Logistics Center</td>\n",
       "      <td>25</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000010</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>Gwanak-gu</td>\n",
       "      <td>True</td>\n",
       "      <td>Wangsung Church</td>\n",
       "      <td>30</td>\n",
       "      <td>37.481735</td>\n",
       "      <td>126.930121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    caseID province             city  group                   infectionSource  \\\n",
       "0  1000001    Seoul       Yongsan-gu   True                     Itaewon Clubs   \n",
       "1  1000002    Seoul        Gwanak-gu   True                           Richway   \n",
       "2  1000003    Seoul          Guro-gu   True               Guro-gu Call Center   \n",
       "3  1000004    Seoul     Yangcheon-gu   True       Yangcheon Table Tennis Club   \n",
       "4  1000005    Seoul        Dobong-gu   True                   Day Care Center   \n",
       "5  1000006    Seoul          Guro-gu   True             Manmin Central Church   \n",
       "6  1000007    Seoul  from other city   True  SMR Newly Planted Churches Group   \n",
       "7  1000008    Seoul    Dongdaemun-gu   True                     Dongan Church   \n",
       "8  1000009    Seoul  from other city   True          Coupang Logistics Center   \n",
       "9  1000010    Seoul        Gwanak-gu   True                   Wangsung Church   \n",
       "\n",
       "   confirmed   latitude   longitude  \n",
       "0        139  37.538621  126.992652  \n",
       "1        119   37.48208  126.901384  \n",
       "2         95  37.508163  126.884387  \n",
       "3         43  37.546061  126.874209  \n",
       "4         43  37.679422  127.044374  \n",
       "5         41  37.481059  126.894343  \n",
       "6         36          -           -  \n",
       "7         17  37.592888  127.056766  \n",
       "8         25          -           -  \n",
       "9         30  37.481735  126.930121  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- code: integer (nullable = true)\n",
      " |-- province: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- elementary_school_count: integer (nullable = true)\n",
      " |-- kindergarten_count: integer (nullable = true)\n",
      " |-- university_count: integer (nullable = true)\n",
      " |-- academy_ratio: double (nullable = true)\n",
      " |-- elderly_population_ratio: double (nullable = true)\n",
      " |-- elderly_alone_ratio: double (nullable = true)\n",
      " |-- nursing_home_count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+\n",
      "|    info_name|          info_value|\n",
      "+-------------+--------------------+\n",
      "|Database Name|               covid|\n",
      "|      Comment|                    |\n",
      "|     Location|file:/home/mosaic...|\n",
      "|        Owner|                    |\n",
      "|   Properties|                    |\n",
      "+-------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_session.sql(\"CREATE DATABASE IF NOT EXISTS COVID COMMENT 'database Covid for testing' ;\")\n",
    "spark_session.sql(\"DESCRIBE DATABASE EXTENDED COVID\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/08/20 17:34:41 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "Unable to infer the schema. The schema specification is required to create the table `COVID`.`regions`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10037/1122891398.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"create table IF NOT EXISTS COVID.regions\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mspark_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"create table IF NOT EXISTS COVID.cases\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'row1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'row2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'row3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \"\"\"\n\u001b[0;32m--> 723\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtableName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Unable to infer the schema. The schema specification is required to create the table `COVID`.`regions`."
     ]
    }
   ],
   "source": [
    "spark_session.sql(\"create table IF NOT EXISTS COVID.regions\")\n",
    "spark_session.sql(\"create table IF NOT EXISTS COVID.cases\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions.write.insertInto(\"COVID.regions\",overwrite=True)\n",
    "cases.write.insertInto(\"COVID.cases\",overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases.write.saveAsTable(\"COVID.cases\")\n",
    "spark_session.sql(\"show tables in test\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listTables(res:pd.core.frame.DataFrame):\n",
    "    obj=res['TABLE_NAME']\n",
    "    list=[]\n",
    "    for x in obj:\n",
    "        list.append(x)\n",
    "    return list\n",
    "def listCols(res:pd.core.frame.DataFrame):\n",
    "    obj=res.columns\n",
    "    list=[]\n",
    "    for c in obj:\n",
    "        list.append(c)\n",
    "    return list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUERY DI TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treeGen(conn,dbName):\n",
    "    #TODO fix this! u lazy!\n",
    "    conn = pyodbc.connect(f'DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={ser};DATABASE={database};UID={user};PWD={password}')\n",
    "    query=\"SELECT * FROM  INFORMATION_SCHEMA.TABLES WHERE TABLE_TYPE='BASE TABLE'\"\n",
    "    res=pd.read_sql(query, conn)\n",
    "    tablesName=listTables(res)\n",
    "    tables=[]\n",
    "    root=Node(dbName,'DB')\n",
    "    for t in tablesName:\n",
    "        tables.append(Node(t,'table'))\n",
    "    root.add_child(tables)\n",
    "    for t in tables:\n",
    "        query=\"SELECT * FROM  {0} \".format(t.data)\n",
    "        res=pd.read_sql(query, conn)\n",
    "        leafs=listCols(res)\n",
    "        for l in leafs:\n",
    "            n=Node(l,'column')\n",
    "            t.add_child(n)\n",
    "    #pprint_tree(root)\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkDF =  spark.createDataFrame(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cali for ODRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycali.vocabulary import ODRLVocabulary\n",
    "odrl = ODRLVocabulary()\n",
    "\n",
    "#odrl.actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AD HOC USER\n",
    "CREATE USER Tester WITH PASSWORD = 'SuperSecure.1'; <br>\n",
    "SELECT * FROM sys.database_principals WHERE authentication_type_desc='DATABASE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL QUERY\n",
    "sql query has this structure\n",
    "<pre>\n",
    "SELECT something FROM some table\n",
    "   WHERE some conditions are satisfied\n",
    "\n",
    "UPDATE some table SET something\n",
    "   WHERE some conditions are satisfied\n",
    "<code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ODRL POLICY TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json,re\n",
    "data={}\n",
    "with open(\"policy.json\") as policy:\n",
    "    data=json.load(policy)\n",
    "print(json.dumps(data, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAINSERVER=\"mosaico.database.windows.net/Test\"\n",
    "\n",
    "def jsonPermissionSearch(data,assignee,targetColumn,targetTable):\n",
    "    for e in data['permission']:\n",
    "        #if rule that define access to the whole table\n",
    "        if e['assignee']==\"{0}:user:{1}\".format(MAINSERVER,assignee) and e['target']==\"{0}:{1}\".format(MAINSERVER,targetTable):\n",
    "            #print(\"rule for the whole table found\")\n",
    "            return e\n",
    "        #rule specific to table:column\n",
    "        elif e['assignee']==\"{0}:user:{1}\".format(MAINSERVER,assignee) and e['target']==\"{0}:{1}:{2}\".format(MAINSERVER,targetTable,targetColumn) and targetColumn!='*':\n",
    "            #print(\"rule for the column found\")\n",
    "            return e\n",
    "        else:\n",
    "            pass\n",
    "    #print('no rule found')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"SELECT * FROM STUDENTI ;SELECT NOME,COGNOME FROM DOCENTI;\"\n",
    "query=query.split(';')\n",
    "#multiple query split-check for select, not for updates\n",
    "completeQueryList=[]\n",
    "for q in query:\n",
    "    if len(q.strip())>0:\n",
    "        res=re.split('SELECT|FROM',q)\n",
    "        res.remove('')\n",
    "        res=[r.strip() for r in res]\n",
    "        #res[0] -> select args\n",
    "        #res[1] -> from args\n",
    "        for column in res[0].split(','):\n",
    "            policy=jsonPermissionSearch(data,'Tester',column,res[1])\n",
    "            if policy and policy['action']=='read':\n",
    "                completeQueryList.append('SELECT {0} FROM {1}'.format(column,res[1]))\n",
    "print(';'.join(completeQueryList))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "Aggregare query appartenenti alla stessa tabella per evitare query eccessive.  \n",
    "Se devo selezionare ad esempio nella tabella ALPHA le tuple con NOME==a , NOME==b , NOME==c  deve risultare in :  \n",
    "    SELECT * FROM ALPHA WHERE NAME in ('a', 'b' , 'c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Json Data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonData='''\n",
    "[{\n",
    "  \"@type\": \"Agreement\",\n",
    "  \"uid\": \"mosaico.database.windows.net/Test:policy:1\",\n",
    "  \"permission\": [{\n",
    "      \"target\": \"mosaico.database.windows.net/Test:STUDENTI\",\n",
    "      \"assignee\": \"mosaico.database.windows.net/Test:user:Tester\",\n",
    "      \"action\": \"read\"\n",
    "  }]\n",
    "  },\n",
    "  {\n",
    "  \"@type\": \"Agreement\",\n",
    "  \"uid\": \"mosaico.database.windows.net/Test:policy:2\",\n",
    "  \"permission\": [\n",
    "    {\n",
    "      \"target\": \"mosaico.database.windows.net/Test:DOCENTI:NOME\",\n",
    "      \"assignee\": \"mosaico.database.windows.net/Test:user:Tester\",\n",
    "      \"action\": \"read\"\n",
    "    }\n",
    "  ]\n",
    "}]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Json parser ad hoc\n",
    "TODO: prevedere gruppi di usr per gli accessi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install parse\n",
    "import json,pprint\n",
    "from parse import *\n",
    "\n",
    "def parseIRIdb(iri):\n",
    "    std_target=\"{serverUrl}/{db}:{table}:{name}\"\n",
    "    p=parse(std_target,iri)\n",
    "    if p==None:\n",
    "        std_target=\"{serverUrl}/{db}:{table}\"\n",
    "        p=parse(std_target,iri)\n",
    "        if p==None:\n",
    "            std_target=\"{serverUrl}/{db}\"\n",
    "            p=parse(std_target,iri)\n",
    "    print(\"\\turl: \\t\\t\",p[\"serverUrl\"])\n",
    "    print(\"\\tdb: \\t\\t\",p[\"db\"])\n",
    "    if \"table\" in p:\n",
    "        print(\"\\ttable: \\t\\t\",p[\"table\"])\n",
    "    if \"name\" in p:\n",
    "        print(\"\\tname: \\t\\t\",p[\"name\"])\n",
    "        \n",
    "def parseIRIusr(iri):\n",
    "    std_target=\"{serverUrl}/{db}:{table}:{name}\"\n",
    "    p=parse(std_target,iri)\n",
    "    print(\"\\tname: \\t\\t\",p[\"name\"])\n",
    "    \n",
    "def parseODLR(jsonData):\n",
    "    doc = json.loads(jsonData)\n",
    "    for rule in doc:\n",
    "        rule_dict=rule.get(\"permission\")[0]\n",
    "        rule_type=rule.get(\"@type\")\n",
    "        rule_id=rule.get(\"uid\")\n",
    "        print(rule_id)\n",
    "        trg=rule_dict.get(\"target\")\n",
    "        parseIRIdb(trg)\n",
    "        ass=rule_dict.get(\"assignee\")\n",
    "        parseIRIusr(ass)\n",
    "        print(\"\\tpermission: \\t\",rule_dict.get(\"action\"))\n",
    "\n",
    "\n",
    "parseODLR(jsonData)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDFLIB time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install rdflib-jsonld\n",
    "from rdflib import Graph, plugin\n",
    "import rdflib\n",
    "g=Graph().parse(data=jsonData,format='json-ld')\n",
    "g.serialize(format='nt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "okString='''{\n",
    "    \"@id\": \"http://example.org/about\",\n",
    "    \"http://purl.org/dc/terms/title\": [\n",
    "        {\n",
    "            \"@type\": \"literal\",\n",
    "            \"@language\": \"en\",\n",
    "            \"@value\": \"Someone's Homepage\"\n",
    "        }\n",
    "    ],\n",
    "    \"@authorization\":\"read\"\n",
    "}'''\n",
    "\n",
    "print(isinstance(okString,dict))\n",
    "g=Graph().parse(data=okString,format='json-ld')\n",
    "list(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TREE GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree1=treeGen(conn,\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authFinder(subject,file,permType='read'):\n",
    "    doc = json.loads(file)\n",
    "    targets=[]\n",
    "    if permType=='read' or permType=='write': #correct permission\n",
    "        rules=[]\n",
    "        for rule in doc:\n",
    "            rule_dict=rule.get(\"permission\")[0]\n",
    "            rule_type=rule.get(\"@type\")\n",
    "            ass=rule_dict.get(\"assignee\")\n",
    "            if rule_type==permType and ass==subject:\n",
    "                trg=rule_dict.get(\"target\")\n",
    "                parseURIdb(trg)\n",
    "                targets.append(trg)\n",
    "        return rules\n",
    "    else:\n",
    "        return false\n",
    "def URIgenerator(Node,server):\n",
    "    rootReached=False\n",
    "    uri=\"\"\n",
    "    while not rootReached:\n",
    "        if uri!=\"\":\n",
    "            uri=Node.data+\":\"+uri\n",
    "        else:\n",
    "            uri=Node.data\n",
    "        if Node.parent!= Node:\n",
    "            Node=Node.parent\n",
    "        else:\n",
    "            rootReached=True\n",
    "    return server+\"/\"+uri\n",
    "\n",
    "def treeAnalyzer(subject,authFile,server,request='read'):\n",
    "    global conn,tree1\n",
    "    auths=authFinder(subject,authFile)\n",
    "    tbaNodes=[]\n",
    "    tbaNodes.append(tree1)\n",
    "    #tbaNodes.append(treeGen(conn,\"Test\")) #SERVER NAME STATICO!\n",
    "    while True:\n",
    "        for node in tbaNodes:\n",
    "            if len(node.children)>0:\n",
    "                for child in node.children:\n",
    "                    x=URIgenerator(child,server)\n",
    "                    print(x)\n",
    "                    tbaNodes.append(child)\n",
    "            tbaNodes.remove(node)\n",
    "        if len(tbaNodes)==0:\n",
    "            break\n",
    "        \n",
    "    else:\n",
    "        print(\"no child nodes\")\n",
    "    #pprint_tree(treeRoot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serv=\"mosaico.database.windows.net\"\n",
    "#pprint_tree(treeGen(conn,\"Test\"))\n",
    "treeAnalyzer(\"Tom\",jsonData,serv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit85632d89df4e44c2866bae0711c269b4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
